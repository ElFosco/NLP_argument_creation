{"cells":[{"cell_type":"markdown","source":["# Installation"],"metadata":{"id":"SWUoqJbhZUaH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHiGJ5Ou8Mwo"},"outputs":[],"source":["!pip install -q tf-models-official"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-VGaZQA8ANi"},"outputs":[],"source":["!pip install tensorflow-text"]},{"cell_type":"markdown","metadata":{"id":"IrxfQlV-7lbr"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmPHpfi8AkgA"},"outputs":[],"source":["import os\n","import shutil\n","\n","import re\n","import numpy as np\n","\n","import pandas as pd\n","\n","import nltk\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","import tensorflow_addons as tfa\n","\n","import keras\n","from keras import backend as K\n","\n","from sklearn import metrics\n","\n","from official.nlp import optimization  # to create AdamW optimizer\n","\n","import seaborn as sns\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"xE_to76fAVf7"},"source":["#Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wn6dyvb0AzdK"},"outputs":[],"source":["# Using google drive to upload the data\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# dir_path = \"drive/MyDrive/NLP_project/Datasets/\"\n","dir_path = \"drive/MyDrive/NLP/\"\n","dataset = \"arg_quality_rank_30k.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ca1VdgDoAURT"},"outputs":[],"source":["df = pd.read_csv(dir_path + dataset)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HC-FCfELNYo"},"outputs":[],"source":["set_topic = df.topic.unique()\n","dict_topic = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKs69SnCMKff"},"outputs":[],"source":["for i in set_topic:\n","  dict_topic[i] = df.loc[i==df['topic'], 'topic'].values.size\n","sorted(dict_topic.items(), key=lambda x: x[1], reverse=True)"]},{"cell_type":"markdown","metadata":{"id":"rV1gnJwQNIZd"},"source":["#Data Preprocessing"]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","def clean_text(text):\n","  text = re.sub('\\\"|-|\\\\\\\\|`', ' ', text)  # delete this chars from the string [\"-\\`]\n","  text = re.sub('\\n', ' ', text)\n","  text = re.sub('^[.]+', '', text)         # delete dots at the beginning of the sentence\n","  text = re.sub(\"([?.!,])\", r\" \\1 \", text)\n","  text = re.sub('\\. \\.', '.', text)        # delete . .\n","  text = re.sub('&', ' and ', text)        # replace & with and\n","  text = re.sub(' +', ' ', text)           # delete additional whitespace\n","  text = text.rstrip()                  \n","  text = text.lstrip()\n","  text = \" \".join([lemmatizer.lemmatize(x) for x in text.split()])\n","  return text"],"metadata":{"id":"nBRUbfFqwIyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['argument'] = df.apply(lambda row : clean_text(row['argument']), axis = 1)\n","df.loc[2, \"argument\"] = \"zero tolerance policy in schools should not be adopted as circumstances are often not black and white, being more nuanced. no one should be written off due to a mistake of judgement.\""],"metadata":{"id":"J6314Kqgy-bl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['argument']"],"metadata":{"id":"Ck4uQ4rOEmSL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQfS-UzU6QXS"},"source":["##Data Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A82m4_1K5pfv"},"outputs":[],"source":["is_training_data =  df['set']=='train'\n","is_validation_data =  df['set']=='dev'\n","is_test_data =  df['set']=='test'\n","\n","training_data = df[is_training_data]\n","validation_data = df[is_validation_data]\n","test_data  = df[is_test_data ]\n","\n","x_train = training_data['argument']\n","Y_train = training_data['MACE-P']\n","\n","x_val = validation_data['argument']\n","Y_val = validation_data['MACE-P']\n","\n","x_test = test_data['argument']\n","Y_test = test_data['MACE-P']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gs14cTT92k-l"},"outputs":[],"source":["x_train.shape"]},{"cell_type":"markdown","metadata":{"id":"a6PDqt2Kfz_T"},"source":["#[Bert](https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8_ctG55-uTX"},"outputs":[],"source":["# @title Choose a BERT model to fine-tune\n","\n","bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  # @param [\"bert_en_uncased_L-24_H-1024_A-16\",\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n","\n","map_name_to_handle = {\n","    'bert_en_uncased_L-24_H-1024_A-16':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4',\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_base/2',\n","    'electra_small':\n","        'https://tfhub.dev/google/electra_small/2',\n","    'electra_base':\n","        'https://tfhub.dev/google/electra_base/2',\n","    'experts_pubmed':\n","        'https://tfhub.dev/google/experts/bert/pubmed/2',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n","}\n","\n","map_model_to_preprocess = {\n","    'bert_en_uncased_L-24_H-1024_A-16':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n","    'electra_small':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'electra_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'experts_pubmed':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","}\n","\n","tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","print(f'BERT model selected           : {tfhub_handle_encoder}')\n","print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gzql3TDrBtg-"},"outputs":[],"source":["bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pduw5iP9Dgz_"},"outputs":[],"source":["bert_model = hub.KerasLayer(tfhub_handle_encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdhOVzGzt1uc"},"outputs":[],"source":["def get_sentence_embeding(sentences):\n","    preprocessed_text = bert_preprocess_model(sentences)\n","    return bert_model(preprocessed_text)['encoder_outputs'][-1][:,0,:]\n","\n","get_sentence_embeding([\n","    \"500$ discount. hurry up\", \n","    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWN6VYotHCw9"},"outputs":[],"source":["def build_classifier_model(dense_size=100):\n","  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","  encoder_inputs = preprocessing_layer(text_input)\n","  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","  outputs = encoder(encoder_inputs)\n","  net = outputs['pooled_output']\n","  net = tf.keras.layers.Dense(dense_size, activation=keras.activations.relu, name='fc')(net)\n","  net = tf.keras.layers.Dense(1, activation=keras.activations.sigmoid, name='classifier')(net)\n","  return tf.keras.Model(text_input, net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_pX1FzsK2uj"},"outputs":[],"source":["classifier_model = build_classifier_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAijDE-crAt4"},"outputs":[],"source":["classifier_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1L4k5p-bIdyq"},"outputs":[],"source":["def pearson_loss(y_true, y_pred):\n","    x = y_true\n","    y = y_pred\n","    mx = K.mean(x, axis=0)\n","    my = K.mean(y, axis=0)\n","    xm, ym = x - mx, y - my\n","    r_num = K.sum(xm * ym)\n","    x_square_sum = K.sum(xm * xm)\n","    y_square_sum = K.sum(ym * ym)\n","    r_den = K.sqrt(x_square_sum * y_square_sum)\n","    r = -r_num / r_den\n","    return K.mean(r)\n","\n","def pearson_metric(y_true, y_pred):\n","    x = y_true\n","    y = y_pred\n","    mx = K.mean(x, axis=0)\n","    my = K.mean(y, axis=0)\n","    xm, ym = x - mx, y - my\n","    r_num = K.sum(xm * ym)\n","    x_square_sum = K.sum(xm * xm)\n","    y_square_sum = K.sum(ym * ym)\n","    r_den = K.sqrt(x_square_sum * y_square_sum)\n","    r = r_num / r_den\n","    return K.mean(r)\n","\n","loss = pearson_loss\n","loss = tf.keras.losses.MeanSquaredError()\n","\n","metric_pearson = pearson_metric\n","metric_mse = tf.keras.metrics.MeanSquaredError()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpXy0Zm7JnbJ"},"outputs":[],"source":["epochs = 1\n","batch_size = 32\n","steps_per_epoch = x_train.shape[0] / batch_size \n","num_train_steps = steps_per_epoch * epochs\n","num_warmup_steps = int(epochs * x_train.shape[0] * 0.1 / batch_size)\n","\n","# solution 1\n","\n","init_lr = 3e-5\n","optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                          num_train_steps=num_train_steps,\n","                                          num_warmup_steps=num_warmup_steps,\n","                                          optimizer_type='adamw')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jI_L17okKvNf"},"outputs":[],"source":["classifier_model.compile(optimizer=optimizer,\n","                         loss=loss,\n","                         metrics=[metric_pearson, metric_mse])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9rUCXRzLhmL"},"outputs":[],"source":["print(f'Training model with {tfhub_handle_encoder}')\n","history = classifier_model.fit(x=x_train, y=Y_train, epochs=epochs, \n","                               batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjGrtWz6Iu8L"},"outputs":[],"source":["loss, metric_1, metric_2 = classifier_model.evaluate(x=x_test, y=Y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcXmtg26cEAG"},"outputs":[],"source":["Y_predicted = classifier_model.predict(x_test)\n","ris = pd.DataFrame(\n","    {'x_test': x_test,\n","     'Y_test': Y_test,\n","     'Y_predicted': list(Y_predicted)\n","    })\n","ris"]},{"cell_type":"markdown","metadata":{"id":"a07yUREWKK8s"},"source":["#Grid Search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQ7fM7G1KNJK"},"outputs":[],"source":["parameters = {'epochs': [1, 2, 3], \n","              'batch_size':[32],\n","              'init_lr': [3e-6, 3e-5],\n","              'dense_size' : [100,200],\n","              'loss' : [tf.keras.losses.MeanSquaredError(), pearson_loss]\n","              }\n","\n","best_scores = -1\n","best_params = {1: dict()}\n","\n","for loss in parameters['loss']:\n","  print(\"Loss: \", loss)\n","  for epochs in parameters['epochs']:\n","    print(\" Epochs: \", epochs)\n","    for init_lr in parameters['init_lr']:\n","      print(\"  Start Learning Rate: \", init_lr)\n","      for batch_size in parameters['batch_size']:\n","        print(\"   Batch Size: \", batch_size)\n","        for dense_size in parameters['dense_size']:\n","          print(\"    Dense size: \", dense_size)\n","          steps_per_epoch = x_train.shape[0] / batch_size \n","          num_train_steps = steps_per_epoch * epochs\n","          num_warmup_steps = int(epochs * x_train.shape[0] * 0.1 / batch_size)\n","          optimizer = optimization.create_optimizer(init_lr=init_lr, \n","                                                    num_train_steps=num_train_steps, \n","                                                    num_warmup_steps=num_warmup_steps, \n","                                                    optimizer_type='adamw')\n","          classifier_model = build_classifier_model(dense_size)\n","          classifier_model.compile(optimizer=optimizer, loss=loss, \n","                                   metrics=[metric_pearson, metric_mse])\n","          history = classifier_model.fit(x=x_train, y=Y_train, epochs=epochs, \n","                                         batch_size=batch_size)\n","          loss_calculated, pearson ,mse = classifier_model.evaluate(x=x_val, \n","                                                                    y=Y_val)\n","          print(\"     Pearson: \", pearson)\n","          print(\"     MSE: \", mse)\n","          if pearson > best_scores:                 \n","            best_score = pearson\n","            best_params = {'epochs': epochs, \n","                           'batch_size': batch_size, \n","                           'start_lr': init_lr,  \n","                           'dense_size': dense_size,\n","                           'loss': loss_calculated}\n","print(best_scores)\n","print(best_params)"]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"JGxguBd7tbb-"}},{"cell_type":"code","source":["# Best parameter found on grid search\n","parameters = {'epochs': 2, \n","              'batch_size': 32,\n","              'init_lr': 3e-5,\n","              'dense_size': 100,\n","              'loss': pearson_loss\n","              }\n","\n","epochs = parameters['epochs']\n","batch_size = parameters['batch_size']\n","init_lr = parameters['init_lr']\n","dense_size = parameters['dense_size']\n","loss = parameters['loss']\n","\n","steps_per_epoch = x_train.shape[0] / batch_size \n","num_train_steps = steps_per_epoch * epochs\n","num_warmup_steps = int(epochs * x_train.shape[0] * 0.1 / batch_size)\n","optimizer = optimization.create_optimizer(init_lr=init_lr, \n","                                          num_train_steps=num_train_steps, \n","                                          num_warmup_steps=num_warmup_steps, \n","                                          optimizer_type='adamw')\n","classifier_model = build_classifier_model(dense_size)\n","classifier_model.compile(optimizer=optimizer, loss=loss, metrics=[metric_pearson, \n","                                                                  metric_mse])\n","history = classifier_model.fit(x=x_train.append(x_val), y=Y_train.append(Y_val), validation_data=(x_test, Y_test), \n","                               epochs=epochs, batch_size=batch_size)\n","loss_calculated, pearson, mse = classifier_model.evaluate(x_test, Y_test)\n","print(\"Pearson: \", pearson)\n","print(\"MSE: \", mse)"],"metadata":{"id":"s8DfZjrPIvy7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save model"],"metadata":{"id":"dTZwGeyPtd4v"}},{"cell_type":"code","source":["classifier_model.save(\"drive/MyDrive/Colab Notebooks/NLP/classifierIBM30k.h5\")"],"metadata":{"id":"R5eU9VjBLV8T"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Predictor_scores.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}