{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perplexity_score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElFosco/NLP_argument_creation/blob/main/perplexity_score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "arh_G6vfbSWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "id": "TBIj-UqQEaEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "IOsJ7DrNbVYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel, OpenAIGPTLMHeadModel\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4edtWl-AyKbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Tqs8o4r8bW2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"
      ],
      "metadata": {
        "id": "Vpdxko2CnSDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "VCos5JOvbj1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset = \"/content/drive/MyDrive/NLP/arg_quality_rank_30k.csv\""
      ],
      "metadata": {
        "id": "ZZASnypzzoQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dataset)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9dlK9c6pz6B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def clean_text(text,topic):\n",
        "  text = re.sub('\\\"|-|\\\\\\\\|`', ' ', text)  # delete this chars from the string [\"-\\`]\n",
        "  text = re.sub('\\n', ' ', text)\n",
        "  text = re.sub('^[.]+', '', text)         # delete dots at the beginning of the sentence\n",
        "  #text = re.sub(\"([?.!,])\", r\" \\1 \", text)\n",
        "  text = re.sub('\\. \\.', '.', text)        # delete . .\n",
        "  text = re.sub('&', ' and ', text)        # replace & with and\n",
        "  text = re.sub(' +', ' ', text)           # delete additional whitespace\n",
        "  text = text.rstrip()                  \n",
        "  text = text.lstrip()\n",
        "  text = \" \".join([lemmatizer.lemmatize(x) for x in text.split()])\n",
        "  if not (re.search('[\\.|?|!]$',text)): #append the topic \n",
        "    text = text+' [SEP]'\n",
        "  else:\n",
        "    text = re.sub('[\\.|?|!]$',' [SEP]',text)\n",
        "  text = text + \" \" + topic.lower()\n",
        "  tokenize_input = tokenizer.tokenize(text)\n",
        "  tokenized = tokenizer.convert_tokens_to_ids(tokenize_input)\n",
        "  return tokenized"
      ],
      "metadata": {
        "id": "_AbpMSUQz9vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[2, \"argument\"] = \"zero tolerance policy in schools should not be adopted as circumstances are often not black and white, being more nuanced. no one should be written off due to a mistake of judgement.\"\n",
        "df['tokenized'] = df.apply(lambda row : clean_text(row['argument'],row['topic']), axis = 1)"
      ],
      "metadata": {
        "id": "_a_FXZ1q0WU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_training_data =  df['set']=='train'\n",
        "is_validation_data =  df['set']=='dev'\n",
        "is_test_data =  df['set']=='test'\n",
        "\n",
        "x_train = df['tokenized'][is_training_data]\n",
        "x_train = x_train.append(df['tokenized'][is_validation_data])\n",
        "x_test  = df['tokenized'][is_test_data]"
      ],
      "metadata": {
        "id": "3qXnwhYTFWWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "uDuIfTz2bhPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_text(df, tokenizer, is_training=False, max_seq_length=None):\n",
        "    \"\"\"\n",
        "    Converts input text sequences using a given tokenizer\n",
        "\n",
        "    :param texts: either a list or numpy ndarray of strings\n",
        "    :tokenizer: an instantiated tokenizer\n",
        "    :is_training: whether input texts are from the training split or not\n",
        "    :max_seq_length: the max token sequence previously computed with\n",
        "    training texts.\n",
        "\n",
        "    :return\n",
        "        text_ids: a nested list on token indices\n",
        "        max_seq_length: the max token sequence previously computed with\n",
        "        training texts.\n",
        "    \"\"\"\n",
        "\n",
        "    # Padding\n",
        "    if is_training:\n",
        "        max_seq_length = int(np.quantile([len(seq) for seq in df], 0.95))\n",
        "    else:\n",
        "        assert max_seq_length is not None\n",
        "\n",
        "    text_ids = [seq + [0] * (max_seq_length - len(seq)) for seq in df]\n",
        "    text_ids = np.array([seq[:max_seq_length] for seq in text_ids])\n",
        "\n",
        "    if is_training:\n",
        "        return text_ids, max_seq_length\n",
        "    else:\n",
        "        return text_ids"
      ],
      "metadata": {
        "id": "rmYGqvAh4FB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tokens, max_seq_length = convert_text(x_train, tokenizer, True)\n",
        "x_test_tokens = convert_text(x_test, tokenizer, False, max_seq_length)\n",
        "print(\"Max token sequence: {}\".format(max_seq_length))\n",
        "print('X train shape: ', x_train_tokens.shape)\n",
        "print('X test shape: ', x_test_tokens.shape)"
      ],
      "metadata": {
        "id": "joKUZEGb4UXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "fvWlGTsObQFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "    \n",
        "    i = -1\n",
        "    for inputs in iter(train_dataloader):\n",
        "        i += 1\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        loss = model(inputs, lm_labels=inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(train_dataloader) + i + 1\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "ov5FeeEAzC9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "best_loss = 1000.0\n",
        "epoch_number = 0\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=6e-5)\n",
        "\n",
        "train_dataloader = DataLoader(x_train_tokens, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(x_test_tokens, batch_size=128, shuffle=False)\n",
        "progress_bar = tqdm(range(EPOCHS*len(train_dataloader)))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.to(device)\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number)\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    valid_steps = 0\n",
        "    model.train(False)\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "      for inputs in iter(test_dataloader):\n",
        "        valid_steps += 1\n",
        "        inputs = inputs.to(device)\n",
        "        loss = model(inputs, lm_labels=inputs)\n",
        "        valid_loss += loss\n",
        "    valid_loss /= valid_steps\n",
        "    print(\"Validation loss: \", valid_loss)\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/model_perplexity_best.th\")\n",
        "\n",
        "    epoch_number += 1\n",
        "print(\"Best valid loss: \", best_loss)"
      ],
      "metadata": {
        "id": "W6ikBJrf0b48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "CEno68tFkotJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score(sentence):\n",
        "    tokenize_input = tokenizer.tokenize(sentence)\n",
        "    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
        "    loss=model(tensor_input, lm_labels=tensor_input)\n",
        "    return math.exp(loss)\n",
        "\n",
        "model.eval()\n",
        "model.to(torch.device('cpu'))\n",
        "sentences=['there a is cat end desk end',\n",
        "                'there is a plane on the desk',\n",
        "                        'there is a book in the desk',\n",
        "           \"there is and made opinion to buy and foolish itself counted celebrate identity and priest's burned\"]\n",
        "\n",
        "scores = [score(i) for i in sentences]\n",
        "print(scores)  # Used to tune alpha\n",
        "a = 70000\n",
        "print([((a-i)/a)**3 for i in scores])"
      ],
      "metadata": {
        "id": "ejEoxKOmhns1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save"
      ],
      "metadata": {
        "id": "hGAr49q9RKb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/model_perplexity_0.th\")"
      ],
      "metadata": {
        "id": "ddN_UVbBRGMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load"
      ],
      "metadata": {
        "id": "YKwrK4FkRIML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/model_perplexity.th\"))"
      ],
      "metadata": {
        "id": "diL-5hrNRJz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}