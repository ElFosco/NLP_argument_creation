{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElFosco/NLP_argument_creation/blob/main/XLNet_STS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mBzLdrdzodb"
      },
      "source": [
        "## Setup\n",
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRHRPImGUth7",
        "outputId": "d3a7f319-824a-4bf5-9414-334094a8e606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy8gUsPuJNyw"
      },
      "source": [
        "Download the pretrained XLNet model and unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfPDGsUtHKG0",
        "outputId": "a7b78a3b-7f8c-4265-ddf0-b72d6dfb4da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-31 09:37:30--  https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.6.128, 142.250.159.128, 74.125.201.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.6.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1338042341 (1.2G) [application/zip]\n",
            "Saving to: ‘cased_L-24_H-1024_A-16.zip’\n",
            "\n",
            "cased_L-24_H-1024_A 100%[===================>]   1.25G  94.6MB/s    in 19s     \n",
            "\n",
            "2022-01-31 09:37:49 (68.2 MB/s) - ‘cased_L-24_H-1024_A-16.zip’ saved [1338042341/1338042341]\n",
            "\n",
            "Archive:  cased_L-24_H-1024_A-16.zip\n",
            "   creating: xlnet_cased_L-24_H-1024_A-16/\n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.index  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.data-00000-of-00001  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/spiece.model  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.meta  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_config.json  \n"
          ]
        }
      ],
      "source": [
        "# only needs to be done once\n",
        "! wget https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\n",
        "! unzip cased_L-24_H-1024_A-16.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uUwjq3BJRbu"
      },
      "source": [
        "Download extract the sts-b dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOGRICbOIsU8",
        "outputId": "cae66655-ca5f-4379-bf56-8e0823fbd76f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-31 09:38:05--  https://dl.fbaipublicfiles.com/glue/data/STS-B.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 802872 (784K) [application/zip]\n",
            "Saving to: ‘STS-B.zip’\n",
            "\n",
            "STS-B.zip           100%[===================>] 784.05K  2.53MB/s    in 0.3s    \n",
            "\n",
            "2022-01-31 09:38:06 (2.53 MB/s) - ‘STS-B.zip’ saved [802872/802872]\n",
            "\n",
            "Archive:  STS-B.zip\n",
            "   creating: STS-B/\n",
            "  inflating: STS-B/LICENSE.txt       \n",
            "  inflating: STS-B/dev.tsv           \n",
            "   creating: STS-B/original/\n",
            "  inflating: STS-B/original/sts-dev.tsv  \n",
            "  inflating: STS-B/original/sts-test.tsv  \n",
            "  inflating: STS-B/original/sts-train.tsv  \n",
            "  inflating: STS-B/readme.txt        \n",
            "  inflating: STS-B/test.tsv          \n",
            "  inflating: STS-B/train.tsv         \n"
          ]
        }
      ],
      "source": [
        "! wget https://dl.fbaipublicfiles.com/glue/data/STS-B.zip\n",
        "! unzip STS-B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGY_ggUUMrwU"
      },
      "source": [
        "Git clone XLNet repo for access to run_classifier and the rest of the xlnet module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r190eYVMpiG",
        "outputId": "4879b18e-e00d-4723-e17d-63edf56ae4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'xlnet'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Total 122 (delta 0), reused 0 (delta 0), pack-reused 122\u001b[K\n",
            "Receiving objects: 100% (122/122), 2.92 MiB | 13.17 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/zihangdai/xlnet.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDP-IaVuPC-z"
      },
      "source": [
        "## Define Variables\n",
        "Define all the dirs: data, xlnet scripts & pretrained model. \n",
        "If you would like to save models then you can authenticate a GCP account and use that for the OUTPUT_DIR & CHECKPOINT_DIR - you will need a large amount storage to fix these models. \n",
        "\n",
        "Alternatively it is easy to integrate a google drive account, checkout this guide for [I/O in colab](https://colab.research.google.com/notebooks/io.ipynb) but rememeber these will take up a large amount of storage. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y7N_xVwavQlV"
      },
      "outputs": [],
      "source": [
        "SCRIPTS_DIR = 'xlnet' #@param {type:\"string\"}\n",
        "DATA_DIR = 'STS-B' #@param {type:\"string\"}\n",
        "OUTPUT_DIR = 'proc_data/STS-B' #@param {type:\"string\"}\n",
        "PRETRAINED_MODEL_DIR = 'xlnet_cased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
        "CHECKPOINT_DIR = 'exp/STS-B' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR6euqwL1KBV"
      },
      "source": [
        "## Run Model\n",
        "This will set off the fine tuning of XLNet. There are a few things to note here:\n",
        "\n",
        "\n",
        "1.   This script will train and evaluate the model\n",
        "2.   This will store the results locally on colab and will be lost when you are disconnected from the runtime\n",
        "3.   This uses the large version of the model (base not released presently)\n",
        "4.   We are using a max seq length of 128 with a batch size of 8 please refer to the [README](https://github.com/zihangdai/xlnet#memory-issue-during-finetuning) for why this is.\n",
        "5. This will take approx 4hrs to run on GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to fix the dependecies issues\n",
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "metadata": {
        "id": "KWMEzYDQ_sdm",
        "outputId": "bd1f7731-d24c-42fc-b32a-7b0baa3c37bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.17.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.37.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=c07e6bd55223cc5fe55b7c15d65339779b573cef00783dddb9aa82aebcce7ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.7.0 requires tensorflow-estimator<2.8,~=2.7.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEMuT6LU0avg",
        "outputId": "3ca2f6c6-312e-429c-9903-1f2e2898ef0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/xlnet/model_utils.py:295: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:855: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:637: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0131 09:40:38.829209 139778454554496 module_wrapper.py:139] From xlnet/run_classifier.py:637: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:637: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0131 09:40:38.829510 139778454554496 module_wrapper.py:139] From xlnet/run_classifier.py:637: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:661: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0131 09:40:38.829855 139778454554496 module_wrapper.py:139] From xlnet/run_classifier.py:661: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:662: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0131 09:40:38.830362 139778454554496 module_wrapper.py:139] From xlnet/run_classifier.py:662: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/xlnet/model_utils.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0131 09:40:38.904997 139778454554496 module_wrapper.py:139] From /content/xlnet/model_utils.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/xlnet/model_utils.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0131 09:40:38.905514 139778454554496 module_wrapper.py:139] From /content/xlnet/model_utils.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Single device mode.\n",
            "I0131 09:40:38.905734 139778454554496 model_utils.py:36] Single device mode.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0131 09:40:38.906027 139778454554496 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I0131 09:40:40.415790 139778454554496 utils.py:159] NumExpr defaulting to 2 threads.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'exp/STS-B', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f204996e190>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I0131 09:40:41.227745 139778454554496 estimator.py:212] Using config: {'_model_dir': 'exp/STS-B', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f204996e190>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function get_model_fn.<locals>.model_fn at 0x7f204996a8c0>) includes params argument, but params are not passed to Estimator.\n",
            "W0131 09:40:41.228278 139778454554496 model_fn.py:630] Estimator's model_fn (<function get_model_fn.<locals>.model_fn at 0x7f204996a8c0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Use tfrecord file proc_data/STS-B/spiece.model.len-128.train.tf_record\n",
            "I0131 09:40:41.228869 139778454554496 run_classifier.py:703] Use tfrecord file proc_data/STS-B/spiece.model.len-128.train.tf_record\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:186: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0131 09:40:41.229211 139778454554496 module_wrapper.py:139] From xlnet/run_classifier.py:186: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Num of train samples: 5749\n",
            "I0131 09:40:41.326187 139778454554496 run_classifier.py:707] Num of train samples: 5749\n",
            "INFO:tensorflow:Create new tfrecord proc_data/STS-B/spiece.model.len-128.train.tf_record.\n",
            "I0131 09:40:41.326664 139778454554496 run_classifier.py:405] Create new tfrecord proc_data/STS-B/spiece.model.len-128.train.tf_record.\n",
            "WARNING:tensorflow:From xlnet/run_classifier.py:407: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0131 09:40:41.327133 139778454554496 module_wrapper.py:139] From xlnet/run_classifier.py:407: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:Writing example 0 of 5749\n",
            "I0131 09:40:41.327614 139778454554496 run_classifier.py:415] Writing example 0 of 5749\n",
            "Traceback (most recent call last):\n",
            "  File \"xlnet/run_classifier.py\", line 855, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"xlnet/run_classifier.py\", line 711, in main\n",
            "    train_file, FLAGS.num_passes)\n",
            "  File \"xlnet/run_classifier.py\", line 418, in file_based_convert_examples_to_features\n",
            "    max_seq_length, tokenize_fn)\n",
            "  File \"/content/xlnet/classifier_utils.py\", line 129, in convert_single_example\n",
            "    label_id = label_map[example.label]\n",
            "KeyError: 4.75\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_command = \"python xlnet/run_classifier.py \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --eval_all_ckpt=False \\\n",
        "  --task_name=sts-b \\\n",
        "  --data_dir=\"+DATA_DIR+\" \\\n",
        "  --output_dir=\"+OUTPUT_DIR+\" \\\n",
        "  --model_dir=\"+CHECKPOINT_DIR+\" \\\n",
        "  --uncased=False \\\n",
        "  --spiece_model_file=\"+PRETRAINED_MODEL_DIR+\"/spiece.model \\\n",
        "  --model_config_path=\"+PRETRAINED_MODEL_DIR+\"/xlnet_config.json \\\n",
        "  --init_checkpoint=\"+PRETRAINED_MODEL_DIR+\"/xlnet_model.ckpt \\\n",
        "  --max_seq_length=128 \\\n",
        "  --train_batch_size=8 \\\n",
        "  --eval_batch_size=8 \\\n",
        "  --num_hosts=1 \\\n",
        "  --num_core_per_host=1 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --train_steps=4000 \\\n",
        "  --warmup_steps=500 \\\n",
        "  --save_steps=500 \\\n",
        "  --iterations=500\"\n",
        "\n",
        "! {train_command}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvhqD-sO0Kyh"
      },
      "source": [
        "## Running & Results\n",
        "These are the results that I got from running this experiment\n",
        "### Params\n",
        "*    --max_seq_length=128 \\\n",
        "*    --train_batch_size= 8 \n",
        "\n",
        "### Times\n",
        "*   Training: 1hr 11mins\n",
        "*   Evaluation: 2.5hr\n",
        "\n",
        "### Results\n",
        "*  Most accurate model on final step\n",
        "*  Accuracy: 0.92416, eval_loss: 0.31708\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUW2avFM_fi_"
      },
      "source": [
        "### Model\n",
        "\n",
        "*   The trained model checkpoints can be found in 'exp/imdb'\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "XLNet-STS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}